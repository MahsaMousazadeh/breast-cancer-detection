# -*- coding: utf-8 -*-
"""BreastCancerClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b0m76nO3kuPIaYI02J9_v6uZ0F4dmIMy

**Developed by Aylar - Taher**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("Breast_Cancer.csv")
df.sample(5)

df['Race'].replace(['White','Black','Other'],[0,1,2],inplace=True)
df['Marital Status'].replace(['Married' ,'Single','Divorced','Widowed','Separated'],[0,1,2,3,4],inplace=True)
df['Status'].replace(['Alive' ,'Dead'],[0,1],inplace=True)
df[['Race','Marital Status']]

df.isnull().sum()

df1=df[['Age','Race','Tumor Size','Regional Node Examined','Reginol Node Positive','Survival Months','Status']]
df1

df1.columns

correlation = df1.corr().round(2)
plt.figure(figsize = (14,7))
sns.heatmap(correlation, annot = True, cmap = 'YlOrBr')

plt.figure(figsize = (25,25))

plt.subplot(6,2,1)
sns.countplot(x = 'Race', palette='Set2', data = df)

plt.subplot(6,2,2)
sns.countplot(x = 'Marital Status', palette='Set2', data = df)

plt.subplot(6,2,3)
sns.countplot(x = 'T Stage ', palette='Set2', data = df)

plt.subplot(6,2,4)
sns.countplot(x = 'N Stage', palette='Set2', data = df)

plt.subplot(6,2,5)
sns.countplot(x = '6th Stage', palette='Set2', data = df)

plt.subplot(6,2,6)
sns.countplot(x = 'differentiate', palette='Set2', data = df)

plt.subplot(6,2,7)
sns.countplot(x = 'A Stage', palette='Set2', data = df)

plt.subplot(6,2,8)
sns.countplot(x = 'Estrogen Status', palette='Set2', data = df)

plt.subplot(6,2,9)
sns.countplot(x = 'Progesterone Status', palette='Set2', data = df)

plt.subplot(6,2,9)
sns.countplot(x = 'Grade', palette='Set2', data = df)

plt.subplot(6,2,11)
sns.countplot(x = 'Status', palette='Set2', data = df)

df['Race'].value_counts()

df['Marital Status'].value_counts()

df['T Stage '].value_counts()

df['N Stage'].value_counts()

df['6th Stage'].value_counts()

df['differentiate'].value_counts()

plt.figure(figsize = (20,20))

plt.subplot(3,2,1)
sns.countplot(x = 'Status', hue= 'Race', palette='Set2', data = df)

plt.subplot(3,2,2)
sns.countplot(x = 'Status', hue= 'Marital Status', palette='Set2', data = df)

plt.subplot(3,2,3)
sns.countplot(x = 'Status', hue= 'differentiate', palette='Set2', data = df)

plt.subplot(3,2,4)
sns.countplot(x = 'Status', hue= 'Grade', palette='Set2', data = df)

plt.subplot(3,2,5)
sns.countplot(x = 'Status', hue= 'T Stage ', palette='Set2', data = df)

plt.subplot(3,2,6)
sns.countplot(x = 'Status', hue= 'N Stage', palette='Set2', data = df)

plt.figure(figsize = (15,10))

plt.subplot(2,2,1)
sns.countplot(x = 'Status', hue= '6th Stage', palette='Set2', data = df)

plt.subplot(2,2,2)
sns.countplot(x = 'Status', hue= 'Estrogen Status', palette='Set2', data = df)

plt.subplot(2,2,3)
sns.countplot(x = 'Status', hue= 'Progesterone Status', palette='Set2', data = df)

X = df1.drop('Status',axis=1)
y = df1['Status']

df1

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=1)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from xgboost import plot_importance

model_LogisticRegression = LogisticRegression()
model_LogisticRegression.fit(X_train, y_train)

model_RandomForestClassifier = RandomForestClassifier(n_estimators = 200)
model_RandomForestClassifier.fit(X_train,y_train)

model_HistGradientBoostingClassifier = HistGradientBoostingClassifier(max_bins=10, learning_rate=0.6)
model_HistGradientBoostingClassifier.fit(X_train, y_train)

model_GaussianNB = GaussianNB()
model_GaussianNB.fit(X_train, y_train)

Y_Pred_LogisticRegression = model_LogisticRegression.predict(X_test)
Y_Pred_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)
Y_Pred_HistGradientBoostingClassifier = model_HistGradientBoostingClassifier.predict(X_test)
Y_Pred_GaussianNB = model_GaussianNB.predict(X_test)

print("Accuracy LogisticRegression: ", str(int(accuracy_score(y_test, Y_Pred_LogisticRegression) * 100)) + "%")
print("Accuracy RandomForestClassifiery: ", str(int(accuracy_score(y_test, Y_Pred_RandomForestClassifier) * 100)) + "%")
print("Accuracy HistGradientBoostingClassifier: ", str(int(accuracy_score(y_test, Y_Pred_HistGradientBoostingClassifier) * 100)) + "%")
print("Accuracy GaussianNB: ", str(int(accuracy_score(y_test, Y_Pred_GaussianNB) * 100)) + "%")

from sklearn.metrics import roc_curve, auc
from matplotlib.pyplot import figure

figure(figsize=(15, 10), dpi=80)

Y_Pred_ay_LogisticRegression = model_LogisticRegression.predict_proba(X_test)
Y_Pred_LogisticRegression = model_LogisticRegression.predict(X_test)

Y_Pred_ay_RandomForestClassifier = model_RandomForestClassifier.predict_proba(X_test)
Y_Pred_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)

Y_Pred_ay_HistGradientBoostingClassifier = model_HistGradientBoostingClassifier.predict_proba(X_test)
Y_Pred_HistGradientBoostingClassifier = model_HistGradientBoostingClassifier.predict(X_test)

Y_Pred_ay_GaussianNB = model_GaussianNB.predict_proba(X_test)
Y_Pred_GaussianNB = model_GaussianNB.predict(X_test)

Y_Pred_ay_LogisticRegression = Y_Pred_ay_LogisticRegression[:, 1]
Y_Pred_RandomForestClassifier = Y_Pred_ay_RandomForestClassifier[:, 1]
Y_Pred_ay_HistGradientBoostingClassifier = Y_Pred_ay_HistGradientBoostingClassifier[:, 1]
Y_Pred_ay_GaussianNB = Y_Pred_ay_GaussianNB[:, 1]

fpr_rf_LogisticRegression, tpr_rf_LogisticRegression, thresholds_rf_LogisticRegression = roc_curve(y_test, Y_Pred_ay_LogisticRegression)
fpr_rf_RandomForestClassifier, tpr_rf_RandomForestClassifier, thresholds_rf__RandomForestClassifier = roc_curve(y_test, Y_Pred_RandomForestClassifier)
fpr_rf_HistGradientBoostingClassifier, tpr_rf_HistGradientBoostingClassifier, thresholds_rf_HistGradientBoostingClassifier = roc_curve(y_test, Y_Pred_ay_HistGradientBoostingClassifier)
fpr_rf_GaussianNB, tpr_rf_GaussianNB, thresholds_rf_GaussianNB = roc_curve(y_test, Y_Pred_ay_GaussianNB)

auc_rf_LogisticRegression = auc(fpr_rf_LogisticRegression, tpr_rf_LogisticRegression)
auc_rf_RandomForestClassifier = auc(fpr_rf_RandomForestClassifier, tpr_rf_RandomForestClassifier)
auc_rf_HistGradientBoostingClassifier = auc(fpr_rf_HistGradientBoostingClassifier, tpr_rf_HistGradientBoostingClassifier)
auc_rf_GaussianNB = auc(fpr_rf_GaussianNB, tpr_rf_GaussianNB)

print("auc LogisticRegression: ", auc_rf_LogisticRegression)
print("auc RandomForestClassifier: ", auc_rf_RandomForestClassifier)
print("auc HistGradientBoostingClassifier: ", auc_rf_HistGradientBoostingClassifier)
print("auc GaussianNB: ", auc_rf_GaussianNB)

fig1 = plt.gcf()

plt.figure(1)
# plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr_rf_HistGradientBoostingClassifier, tpr_rf_HistGradientBoostingClassifier, label='Histogram-based Gradient Boosting (AUROC = {:.3f})'.format(auc_rf_HistGradientBoostingClassifier))
plt.plot(fpr_rf_LogisticRegression, tpr_rf_LogisticRegression, label='Logistic Regression (AUROC = {:.3f})'.format(auc_rf_LogisticRegression))
plt.plot(fpr_rf_GaussianNB, tpr_rf_GaussianNB, label='Gaussian Naive Bayes (AUROC = {:.3f})'.format(auc_rf_GaussianNB))
plt.plot(fpr_rf_RandomForestClassifier, tpr_rf_RandomForestClassifier, label='Random Forest Classifier (AUROC = {:.3f})'.format(auc_rf_RandomForestClassifier))

plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()

from google.colab import files
fig1.savefig("ROC_Curve.png", dpi=200)
files.download("ROC_Curve.png")

from sklearn.metrics import precision_recall_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, precision_recall_fscore_support
from sklearn.metrics import confusion_matrix


Y_Pred_ay_LogisticRegression = model_LogisticRegression.predict_proba(X_test)
Y_LogisticRegression = model_LogisticRegression.predict(X_test)
Y_Pred_ay_RandomForestClassifier = model_RandomForestClassifier.predict_proba(X_test)
Y_RandomForestClassifier = model_RandomForestClassifier.predict(X_test)
Y_Pred_ay_HistGradientBoostingClassifier = model_HistGradientBoostingClassifier.predict_proba(X_test)
Y_HistGradientBoostingClassifier = model_HistGradientBoostingClassifier.predict(X_test)
Y_Pred_ay_GaussianNB = model_GaussianNB.predict_proba(X_test)
Y_GaussianNB = model_GaussianNB.predict(X_test)

Y_Pred_ay_LogisticRegression = Y_Pred_ay_LogisticRegression[:, 1]
Y_Pred_ay_RandomForestClassifier = Y_Pred_ay_RandomForestClassifier[:, 1]
Y_Pred_ay_HistGradientBoostingClassifier = Y_Pred_ay_HistGradientBoostingClassifier[:, 1]
Y_Pred_ay_GaussianNB = Y_Pred_ay_GaussianNB[:, 1]

lr_precision_LogisticRegression, lr_recall_LogisticRegression, _ = precision_recall_curve(y_test, Y_Pred_ay_LogisticRegression)
lr_precision_RandomForestClassifier, lr_recall_RandomForestClassifier, _ = precision_recall_curve(y_test, Y_Pred_ay_RandomForestClassifier)
lr_precision_HistGradientBoostingClassifier, lr_recall_HistGradientBoostingClassifier, _ = precision_recall_curve(y_test, Y_Pred_ay_HistGradientBoostingClassifier)
lr_precision_GaussianNB, lr_recall_GaussianNB, _ = precision_recall_curve(y_test, Y_Pred_ay_GaussianNB)


tn_ay_LogisticRegression, fp_ay_LogisticRegression, fn_ay_LogisticRegression, tp_ay_LogisticRegression = confusion_matrix(y_test, Y_LogisticRegression).ravel()
tn_ay_RandomForestClassifie, fp_ay_RandomForestClassifie, fn_ay_RandomForestClassifie, tp_ay_RandomForestClassifie = confusion_matrix(y_test, Y_RandomForestClassifier).ravel()
tn_ay_HistGradientBoostingClassifier, fp_ay_HistGradientBoostingClassifier, fn_ay_HistGradientBoostingClassifier, tp_ay_HistGradientBoostingClassifier = confusion_matrix(y_test, Y_HistGradientBoostingClassifier).ravel()
tn_ay_GaussianNB, fp_ay_GaussianNB, fn_ay_GaussianNB, tp_ay_GaussianNB = confusion_matrix(y_test, Y_GaussianNB).ravel()


precision_score_ay_LogisticRegression = tp_ay_LogisticRegression / (tp_ay_LogisticRegression + fp_ay_LogisticRegression)
recall_score_ay_LogisticRegression = tp_ay_LogisticRegression / (tp_ay_LogisticRegression + fn_ay_LogisticRegression)
specificity_ay_LogisticRegression = tn_ay_LogisticRegression / (tn_ay_LogisticRegression + fp_ay_LogisticRegression)
f1_ay_LogisticRegression = 2*(recall_score_ay_LogisticRegression * precision_score_ay_LogisticRegression) / (recall_score_ay_LogisticRegression + precision_score_ay_LogisticRegression)

precision_score_ay_RandomForestClassifier = tp_ay_RandomForestClassifie / (tp_ay_RandomForestClassifie + fp_ay_RandomForestClassifie)
recall_score_ay_RandomForestClassifier = tp_ay_RandomForestClassifie / (tp_ay_RandomForestClassifie + fn_ay_RandomForestClassifie)
specificity_ay_RandomForestClassifier = tn_ay_RandomForestClassifie / (tn_ay_RandomForestClassifie + fp_ay_RandomForestClassifie)
f1_ay_RandomForestClassifier = 2 * (recall_score_ay_RandomForestClassifier * precision_score_ay_RandomForestClassifier) / (recall_score_ay_RandomForestClassifier + precision_score_ay_RandomForestClassifier)

precision_score_ay_HistGradientBoostingClassifier = tp_ay_HistGradientBoostingClassifier / (tp_ay_HistGradientBoostingClassifier + fp_ay_HistGradientBoostingClassifier)
recall_score_ay_HistGradientBoostingClassifier = tp_ay_HistGradientBoostingClassifier / (tp_ay_HistGradientBoostingClassifier + fn_ay_HistGradientBoostingClassifier)
specificity_ay_HistGradientBoostingClassifier = tn_ay_HistGradientBoostingClassifier / (tn_ay_HistGradientBoostingClassifier + fp_ay_HistGradientBoostingClassifier)
f1_ay_HistGradientBoostingClassifier = 2 * (recall_score_ay_HistGradientBoostingClassifier * precision_score_ay_HistGradientBoostingClassifier) / (recall_score_ay_HistGradientBoostingClassifier + precision_score_ay_HistGradientBoostingClassifier)

precision_score_ay_GaussianNB = tp_ay_GaussianNB / (tp_ay_GaussianNB + fp_ay_GaussianNB)
recall_score_ay_GaussianNB = tp_ay_GaussianNB / (tp_ay_GaussianNB + fn_ay_GaussianNB)
specificity_ay_GaussianNB = tn_ay_GaussianNB / (tn_ay_GaussianNB + fp_ay_GaussianNB)
f1_ay_GaussianNB = 2 * (recall_score_ay_GaussianNB * precision_score_ay_GaussianNB) / (recall_score_ay_GaussianNB + precision_score_ay_GaussianNB)

print("F1-score (aka F-Score / F-Measure)")

print("Logistic Regression", f1_ay_LogisticRegression)
print("Random Forest Classifier", f1_ay_RandomForestClassifier)
print("Histogram-based Gradient Boosting", f1_ay_HistGradientBoostingClassifier)
print("Gaussian Naive Bayes", f1_ay_GaussianNB)

print("Precision")

print("Logistic Regression", precision_score_ay_LogisticRegression)
print("Random Forest Classifier", precision_score_ay_RandomForestClassifier)
print("Histogram-based Gradient Boosting", precision_score_ay_HistGradientBoostingClassifier)
print("Gaussian Naive Bayes", precision_score_ay_GaussianNB)

print("Recall (aka Sensitivity)")

print("Logistic Regression", recall_score_ay_LogisticRegression)
print("Random Forest Classifier", recall_score_ay_RandomForestClassifier)
print("Histogram-based Gradient Boosting", recall_score_ay_HistGradientBoostingClassifier)
print("Gaussian Naive Bayes", recall_score_ay_GaussianNB)

print("Specificity")

print("Logistic Regression", specificity_ay_LogisticRegression)
print("Random Forest Classifier",  specificity_ay_RandomForestClassifier)
print("Histogram-based Gradient Boosting",  specificity_ay_HistGradientBoostingClassifier)
print("Gaussian Naive Bayes",  specificity_ay_GaussianNB)

fig1 = plt.gcf()

# plt.rcParams['figure.figsize'] = [20, 15]
plt.figure(1)

plt.plot(lr_recall_HistGradientBoostingClassifier, lr_precision_HistGradientBoostingClassifier, label='Histogram-based Gradient Boosting')
plt.plot(lr_recall_LogisticRegression, lr_precision_LogisticRegression, label='Logistic Regression')
plt.plot(lr_recall_GaussianNB, lr_precision_GaussianNB, label='Gaussian Naive Bayes')
plt.plot(lr_recall_RandomForestClassifier, lr_precision_RandomForestClassifier, label='Random Forest Classifier')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc='best')
plt.title('Precision-Recall Curve')
plt.show()

from google.colab import files
fig1.savefig("Precision-Recall.png", dpi=200)
files.download("Precision-Recall.png")